{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876d30a4-c2c1-4060-a7dc-8252e79014dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR=\"Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics. Typically data is collected in text corpora, using either rule-based, statistical or neural-based approaches in machine learning and deep learning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562f0f6c-3020-4981-831e-0c3a1975c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics. Typically data is collected in text corpora, using either rule-based, statistical or neural-based approaches in machine learning and deep learning.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e25aaac-90d9-46e2-a93e-4d982c8bf33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest word tokenizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bd4b63-0e75-482d-bff5-56d429f95011",
   "metadata": {},
   "outputs": [],
   "source": [
    "toke=word_tokenize(VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36eecbc0-c4d2-4afc-8ea1-c2eb657bc245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'especially',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'primarily',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'providing',\n",
       " 'computers',\n",
       " 'with',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'process',\n",
       " 'data',\n",
       " 'encoded',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'and',\n",
       " 'is',\n",
       " 'thus',\n",
       " 'closely',\n",
       " 'related',\n",
       " 'to',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " ',',\n",
       " 'knowledge',\n",
       " 'representation',\n",
       " 'and',\n",
       " 'computational',\n",
       " 'linguistics',\n",
       " ',',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics',\n",
       " '.',\n",
       " 'Typically',\n",
       " 'data',\n",
       " 'is',\n",
       " 'collected',\n",
       " 'in',\n",
       " 'text',\n",
       " 'corpora',\n",
       " ',',\n",
       " 'using',\n",
       " 'either',\n",
       " 'rule-based',\n",
       " ',',\n",
       " 'statistical',\n",
       " 'or',\n",
       " 'neural-based',\n",
       " 'approaches',\n",
       " 'in',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'deep',\n",
       " 'learning',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0daee0ea-d108-4457-9e27-cfb70ccc15ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to', 'these', \"you'd\", \"mightn't\", 'what', 'am', \"hadn't\", 'during', 'some', 'ours', 'her', 'into', 'ain', \"don't\", 'in', 'does', 'most', 'your', 'below', 'an', 'shan', 'than', 'how', 'isn', 'd', 'both', 'herself', 'yourselves', 'haven', 'had', 'a', 'it', 'for', 'again', 'only', 'out', \"aren't\", \"won't\", 'which', 'itself', 'doing', 'as', \"needn't\", 'she', 'those', 'o', 'was', 'through', 'theirs', 'when', 'i', \"you've\", 'needn', 'who', 'on', \"didn't\", 'won', \"wouldn't\", 'or', 'hadn', 'from', 'off', 'aren', 'will', 'any', 'before', 'where', 'its', 'don', 'up', 'but', 'so', 'wouldn', 'too', \"doesn't\", 'at', \"couldn't\", 'm', 'we', 'because', 'against', 'each', 'nor', 'once', 'y', \"shan't\", 'the', 's', 'should', 'about', 'is', 'himself', 'themselves', 'of', 'very', 'under', 'not', 'by', 'him', \"mustn't\", 'can', 'yourself', 'you', 'been', 'over', 'now', 'are', 'until', 'just', 'doesn', \"shouldn't\", 'my', 'hasn', 'there', 're', 'have', 'and', 'myself', 'me', \"haven't\", \"wasn't\", 'shouldn', 'same', 'did', 'above', 'our', 'yours', 'he', 'down', 'while', 'having', 'do', 'few', 'ourselves', 'his', 'other', \"hasn't\", 'wasn', 'with', 'that', 'ma', \"she's\", \"should've\", \"you're\", 'this', 'further', 'couldn', 'if', 'being', 'be', 'has', 'weren', 'they', \"it's\", \"you'll\", 'were', 'mightn', 'more', 've', 'didn', \"isn't\", \"weren't\", 'mustn', 'hers', \"that'll\", 'between', 'here', 'no', 't', 'll', 'whom', 'their', 'such', 'own', 'after', 'them', 'all', 'then', 'why'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# apply stopp word remooval\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download the stopwords dataset (only needed once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "print(stop_words)  # Display the stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "468784fb-d6b5-4285-8477-5c59d0baa703",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9071da19-8aee-405e-9b24-772f6bdda076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d16fbe-1e18-4b1b-bedf-2bad35352fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
